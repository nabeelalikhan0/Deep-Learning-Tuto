{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fe00dee",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# 🎨 What is **TensorBoard**?\n",
    "\n",
    "---\n",
    "\n",
    "## 🧸 1. Baby-Level Definition:\n",
    "\n",
    "> **TensorBoard** is a tool that lets you **SEE** how your neural network is learning — like a **diary with graphs, charts, and pictures**.\n",
    "\n",
    "Imagine your AI model is going to school 📚 —\n",
    "**TensorBoard is the notebook** where it writes:\n",
    "\n",
    "* “How much did I learn today?”\n",
    "* “Am I making fewer mistakes?”\n",
    "* “What do my weights look like?”\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 2. Why Use TensorBoard?\n",
    "\n",
    "Because deep learning is **invisible magic** under the hood.\n",
    "You want to **see and understand** what’s happening inside.\n",
    "\n",
    "TensorBoard helps you:\n",
    "\n",
    "| 📊 What You See         | 🧠 Why It Matters                          |\n",
    "| ----------------------- | ------------------------------------------ |\n",
    "| Loss graph 📉           | Am I improving? Is loss going down?        |\n",
    "| Accuracy graph ✅        | How many predictions are correct?          |\n",
    "| Learning rate change 📈 | Is the model learning faster or slower?    |\n",
    "| Model structure 🧱      | What layers does my model have?            |\n",
    "| Histograms 📦           | What do weights/gradients look like?       |\n",
    "| Image previews 🖼️      | See input images, filters, feature maps    |\n",
    "| Text/audio/embeddings   | See output from NLP or embeddings visually |\n",
    "\n",
    "---\n",
    "\n",
    "## 🛠️ 3. How TensorBoard Works (Simplified)\n",
    "\n",
    "1. **You train a model**\n",
    "2. You tell it: “✍️ Write logs in a folder”\n",
    "3. **TensorBoard reads those logs**\n",
    "4. You visit a website (usually `localhost:6006`) to **see the graphs** 📊\n",
    "\n",
    "---\n",
    "\n",
    "## 💻 4. Basic Example with PyTorch or TensorFlow\n",
    "\n",
    "### For TensorFlow:\n",
    "\n",
    "```python\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "\n",
    "# Create a logger\n",
    "tb = TensorBoard(log_dir=\"logs/\")\n",
    "\n",
    "# Fit your model with logging\n",
    "model.fit(X, y, epochs=10, callbacks=[tb])\n",
    "```\n",
    "\n",
    "Then run in terminal:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=logs/\n",
    "```\n",
    "\n",
    "Open in browser:\n",
    "👉 [http://localhost:6006/](http://localhost:6006/)\n",
    "\n",
    "---\n",
    "\n",
    "### For PyTorch:\n",
    "\n",
    "```python\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "writer = SummaryWriter('runs/exp1')\n",
    "\n",
    "for epoch in range(10):\n",
    "    loss = some_loss_function()\n",
    "    writer.add_scalar('Loss/train', loss, epoch)\n",
    "\n",
    "writer.close()\n",
    "```\n",
    "\n",
    "Then:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir=runs\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📸 5. Real Analogy: Baby's Growth Chart 📈\n",
    "\n",
    "Imagine a baby 👶 learning to walk (your model).\n",
    "\n",
    "* Day 1: Takes 2 steps (loss = high)\n",
    "* Day 10: Takes 100 steps (loss = low)\n",
    "\n",
    "You’re drawing a chart of this progress on your wall 🧱.\n",
    "That wall? — **TensorBoard!**\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 6. Components of TensorBoard\n",
    "\n",
    "| Component  | Description                        |\n",
    "| ---------- | ---------------------------------- |\n",
    "| Scalars    | Line charts (loss, accuracy, etc.) |\n",
    "| Graph      | Structure of your model (layers)   |\n",
    "| Histograms | Distribution of weights/gradients  |\n",
    "| Images     | Visual input/output data           |\n",
    "| Projector  | 2D/3D view of embeddings           |\n",
    "| Audio/Text | For NLP & audio data visualization |\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 TL;DR\n",
    "\n",
    "> **TensorBoard** is like a microscope 🔬 and a diary 📔 for your AI model.\n",
    "> It shows **how learning is going**, **where it’s failing**, and **what it looks like inside**.\n",
    "\n",
    "You run it, and **see your model's brain live**.\n",
    "\n",
    "---\n",
    "\n",
    "### Here we are using the name file as we used in you handwritten digits classificaiton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "563fba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b7f5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test) = keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "58bfae8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "63f2a779",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28, 28), 784)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape , 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cb02d394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8a1b6ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "275f22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now here we are scalling values to 0 to 1 and we know that the pixel values are between 0 to 255 so we will devide the variables by 255\n",
    "\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# you can check the accuracy without this it will be slight lower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9803b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_flattened = X_train.reshape(len(X_train),28*28) # Converting two dimensional data to one dimensional\n",
    "X_test_flattened = X_test.reshape(len(X_test),28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29f17f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (10000, 784))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_flattened.shape , X_test_flattened.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78b1ef2",
   "metadata": {},
   "source": [
    "<center><h1 style=\"color:red; hover\">Here we're starting the tesorboard</h1></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e56b75e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nabeel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "c:\\Users\\Nabeel\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.7205 - loss: 1.0556\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.8983 - loss: 0.3648\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 6ms/step - accuracy: 0.9144 - loss: 0.3036\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9238 - loss: 0.2702\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9297 - loss: 0.2515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a50b9a9350>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if you are tired of flatterning the images you can use the flattern hidden layer\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(100,input_shape=(784,),activation='relu'),\n",
    "    keras.layers.Dense(10,activation='sigmoid')\n",
    "\n",
    "])\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"../logs/SGD_2.2\",histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer='SGD',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.fit(X_train,y_train,epochs=5 ,callbacks=[tb_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9d734427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 0.4532\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9629 - loss: 0.1304\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 11ms/step - accuracy: 0.9741 - loss: 0.0864\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 9ms/step - accuracy: 0.9817 - loss: 0.0633\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 6ms/step - accuracy: 0.9845 - loss: 0.0490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1a50b9aacd0>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now if you are tired of flatterning the images you can use the flattern hidden layer\n",
    "\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(100,input_shape=(784,),activation='relu'),\n",
    "    keras.layers.Dense(10,activation='sigmoid')\n",
    "\n",
    "])\n",
    "\n",
    "tb_callback = tf.keras.callbacks.TensorBoard(log_dir=\"../logs/adam_2.2\",histogram_freq=1)\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.fit(X_train,y_train,epochs=5 ,callbacks=[tb_callback]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db2b1925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9246 - loss: 0.2628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.22914057970046997, 0.9348999857902527]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd084a8",
   "metadata": {},
   "source": [
    "## Now run tensorboard --logdir logs/ this in the terminal\n",
    "\n",
    "you can also use the tensorboard in the notebook itself\n",
    "\n",
    "by using these cmds\n",
    "\n",
    "%load_ext tensorboard <br>\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58708309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 3584), started 0:08:42 ago. (Use '!kill 3584' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-caaac4067fa6263e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-caaac4067fa6263e\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6007;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25648c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'kill' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!kill 3584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eeb9b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
